version: '3.8'

networks:
  bigdata:
    driver: bridge

volumes:
  hadoop_namenode:
  hadoop_datanode:
  postgres_hive:

services:
  # =========================
  # HADOOP CORE
  # =========================
  
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    restart: always
    ports:
      - "9870:9870"  # Namenode Web UI
      - "8020:8020"  # Namenode RPC
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - ./data:/data
    environment:
      - CLUSTER_NAME=test-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_replication=1
    networks:
      - bigdata

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    restart: always
    ports:
      - "9864:9864"  # Datanode Web UI
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_replication=1
    depends_on:
      - namenode
    networks:
      - bigdata

  # =========================
  # HIVE CORE
  # =========================
  
  postgres-hive:
    image: postgres:13-alpine
    container_name: hive-postgres
    restart: always
    ports:
      - "5433:5432"
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive123
    volumes:
      - postgres_hive:/var/lib/postgresql/data
    networks:
      - bigdata

  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    restart: always
    ports:
      - "9083:9083"
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      SERVICE_OPTS: "-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres-hive:5432/metastore -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=hive123"
    depends_on:
      - postgres-hive
      - namenode
    networks:
      - bigdata

  hiveserver2:
    image: apache/hive:3.1.3
    container_name: hive-server2
    restart: always
    ports:
      - "10000:10000"  # HiveServer2 Thrift
      - "10002:10002"  # HiveServer2 Web UI
    environment:
      SERVICE_NAME: hiveserver2
      SERVICE_OPTS: "-Dhive.metastore.uris=thrift://hive-metastore:9083"
      IS_RESUME: "true"
    depends_on:
      - hive-metastore
    networks:
      - bigdata

  # =========================
  # SPARK STANDALONE
  # =========================
  
  spark-master:
    image: bitnami/spark:3.4.3
    container_name: spark-master
    restart: always
    ports:
      - "8080:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./apps:/workspace
    networks:
      - bigdata

  spark-worker:
    image: bitnami/spark:3.4.3
    container_name: spark-worker
    restart: always
    ports:
      - "8081:8081"  # Spark Worker Web UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    networks:
      - bigdata
